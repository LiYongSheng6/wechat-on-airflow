version: '3.8'

# 基础配置
x-common: &common
  restart: unless-stopped
  networks:
    - airflow-network

# Airflow基础配置
x-airflow-common: &airflow-common
  <<: *common
  image: bitnami/airflow:latest
  volumes: &airflow-volumes
    - ./dags:/opt/bitnami/airflow/dags
    - ./logs:/opt/bitnami/airflow/logs
    - .requirements.txt:/bitnami/python/requirements.txt
  depends_on:
    redis:
      condition: service_healthy
    postgresql:
      condition: service_healthy

# Airflow环境变量
x-airflow-env: &airflow-env
  # 基础配置
  AIRFLOW_FERNET_KEY: &fernet_key 46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
  AIRFLOW_SECRET_KEY: &secret_key a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
  AIRFLOW_EXECUTOR: CeleryExecutor
  AIRFLOW_LOAD_EXAMPLES: no
  
  # 数据库配置
  AIRFLOW_DATABASE_NAME: &db_name ${AIRFLOW_DATABASE_NAME}
  AIRFLOW_DATABASE_USERNAME: &db_user ${AIRFLOW_DATABASE_USERNAME}
  AIRFLOW_DATABASE_PASSWORD: &db_pass ${AIRFLOW_DATABASE_PASSWORD}
  
  # 核心配置
  AIRFLOW__CORE__PARALLELISM: 8
  AIRFLOW__CORE__DAG_CONCURRENCY: 4
  AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 3
  AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Shanghai
  
  # 其他配置
  TZ: Asia/Shanghai
  AIRFLOW__CELERY__BROKER_CONNECTION_RETRY_ON_STARTUP: True
  AIRFLOW__SCHEDULER__STANDALONE_DAG_PROCESSOR: True

services:
  postgresql:
    <<: *common
    image: bitnami/postgresql:latest
    container_name: airflow_postgres
    environment: 
      POSTGRESQL_DATABASE: *db_name
      POSTGRESQL_USERNAME: *db_user
      POSTGRESQL_PASSWORD: *db_pass
    volumes:
      - postgres-data:/bitnami/postgresql
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5

  # 添加初始化服务
  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    command: bash -c "
      airflow db init &&
      airflow users create
        --username ${AIRFLOW_USERNAME}
        --firstname admin
        --lastname admin
        --role Admin
        --email ${AIRFLOW_EMAIL}
        --password ${AIRFLOW_PASSWORD}
      "
    environment:
      <<: *airflow-env
    depends_on:
      postgresql:
        condition: service_healthy

  redis:
    <<: *common
    image: bitnami/redis:latest
    container_name: airflow_redis
    environment:
      ALLOW_EMPTY_PASSWORD: yes
    volumes:
      - redis-data:/bitnami
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    environment:
      <<: *airflow-env
      AIRFLOW_COMPONENT_TYPE: scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy

  airflow-worker:
    <<: *airflow-common
    container_name: airflow_worker
    environment:
      <<: *airflow-env
      AIRFLOW_COMPONENT_TYPE: worker
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy

  airflow:
    <<: *airflow-common
    container_name: airflow_web
    ports:
      - '80:8080'
    environment:
      <<: *airflow-env
      AIRFLOW_COMPONENT_TYPE: webserver
      AIRFLOW_USERNAME: ${AIRFLOW_USERNAME}
      AIRFLOW_PASSWORD: ${AIRFLOW_PASSWORD}
      AIRFLOW_EMAIL: ${AIRFLOW_EMAIL}
      # API配置
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      AIRFLOW__API__ACCESS_CONTROL_ALLOW_HEADERS: "*"
      AIRFLOW__API__ACCESS_CONTROL_ALLOW_METHODS: "*"
      AIRFLOW__API__ACCESS_CONTROL_ALLOW_ORIGINS: "*"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy

  airflow-dag-processor:
    <<: *airflow-common
    container_name: airflow_dag_processor
    environment:
      <<: *airflow-env
      AIRFLOW_COMPONENT_TYPE: dag-processor
      AIRFLOW__SCHEDULER__DAG_FILE_PROCESSOR_TIMEOUT: 600
      AIRFLOW__SCHEDULER__PARSING_PROCESSES: 2
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy

  airflow-triggerer:
    <<: *airflow-common
    container_name: airflow_triggerer
    environment:
      <<: *airflow-env
      AIRFLOW_COMPONENT_TYPE: triggerer
      AIRFLOW__TRIGGERER__DEFAULT_CAPACITY: 1000
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy

volumes:
  postgres-data:
  redis-data:

networks:
  airflow-network:
    driver: bridge
